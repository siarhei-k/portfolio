{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227afe3b",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "\n",
    "This project serves as a **proof-of-concept (PoC)** for a **multitask LLM-powered chatbot prototype** designed for **Car-ing is sharing**, a growing car sales and rental company targeting international customers â€” particularly in **Spain**.\n",
    "\n",
    "The goal is to demonstrate how **pre-trained Large Language Models (LLMs)** can be used to:\n",
    "1. Classify customer sentiment in car reviews\n",
    "2. Translate key content into Spanish for local customers\n",
    "3. Extract meaningful insights via Question Answering (QA)\n",
    "4. Summarize long reviews for quick ingestion\n",
    "5. Evaluate model outputs using standardized metrics\n",
    "\n",
    "This PoC lays the foundation for a scalable, multilingual customer support chatbot that can:\n",
    "- Analyze real-time feedback\n",
    "- Answer user questions in multiple languages\n",
    "- Detect toxic or negative sentiment\n",
    "- Provide concise summaries of vehicle experiences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abc6632",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset contains **customer reviews** of various Nissan vehicles, each labeled as either `POSITIVE` or `NEGATIVE`. This small but representative dataset simulates real-world user feedback.\n",
    "\n",
    "| `Review ID` | `Vehicle` | `Sentiment` |\n",
    "\n",
    "> âœ… **Note:** The dataset is intentionally small for rapid prototyping and demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a2ce4",
   "metadata": {},
   "source": [
    "### Tools & Libraries Used\n",
    "\n",
    "| Library | Purpose |\n",
    "|-------|--------|\n",
    "| `pandas` | Data loading and manipulation |\n",
    "| `transformers` (Hugging Face) | Access to pre-trained models |\n",
    "| `evaluate` | Standardized metric computation |\n",
    "| `pipeline` | High-level API for NLP tasks |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "854bf5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import evaluate\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac0a56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "reviews = pd.read_csv('car_reviews.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12a6ce9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am very satisfied with my 2014 Nissan NV SL....</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The car is fine. It's a bit loud and not very ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My first foreign car. Love it, I would buy ano...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've come across numerous reviews praising the...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been dreaming of owning an SUV for quite ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     Class\n",
       "0  I am very satisfied with my 2014 Nissan NV SL....  POSITIVE\n",
       "1  The car is fine. It's a bit loud and not very ...  NEGATIVE\n",
       "2  My first foreign car. Love it, I would buy ano...  POSITIVE\n",
       "3  I've come across numerous reviews praising the...  NEGATIVE\n",
       "4  I've been dreaming of owning an SUV for quite ...  POSITIVE"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows for inspection\n",
    "reviews.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5ca3a0",
   "metadata": {},
   "source": [
    "### âœ… Sentiment Classification\n",
    "\n",
    "ObjectiveClassify each review as **POSITIVE** or **NEGATIVE** using a fine-tuned DistilBERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9112ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample outputs: [{'label': 'POSITIVE', 'score': 0.9293985366821289}, {'label': 'POSITIVE', 'score': 0.8654282093048096}, {'label': 'POSITIVE', 'score': 0.9994640946388245}]\n",
      "predictions (first 10): [1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Initialize sentiment classification pipeline\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "# convert the pandas Series to a plain list of strings and run the model\n",
    "predicted_labels = sentiment_pipeline(reviews['Review'].tolist())\n",
    "\n",
    "# extract labels and map to binary integers: POSITIVE -> 1, NEGATIVE -> 0\n",
    "predictions = [1 if pred[\"label\"] == \"POSITIVE\" else 0 for pred in predicted_labels]\n",
    "\n",
    "print('sample outputs:', predicted_labels[:3])\n",
    "print('predictions (first 10):', predictions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aded6b",
   "metadata": {},
   "source": [
    "#### âœ… Evaluation\n",
    "We compute:\n",
    "- **Accuracy**: Proportion of correct predictions\n",
    "- **F1 Score**: Harmonic mean of precision and recall (ideal for imbalanced data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0654083a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "F1 Score: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "references = [1 if review == \"POSITIVE\" else 0 for review in reviews['Class'].tolist()]\n",
    "\n",
    "# Compute metrics\n",
    "accuracy_compute = accuracy.compute(predictions=predictions, references=references)\n",
    "f1_compute = f1.compute(predictions=predictions, references=references)\n",
    "\n",
    "accuracy_result = accuracy_compute['accuracy']\n",
    "f1_result = f1_compute['f1']\n",
    "\n",
    "print('Accuracy:', accuracy_result)\n",
    "print('F1 Score:', f1_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2166743c",
   "metadata": {},
   "source": [
    "> âœ… **Insight:** The model performs well, correctly classifying 4 out of 5 reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c5860",
   "metadata": {},
   "source": [
    "### âœ… English-to-Spanish Translation\n",
    "\n",
    "**Objective** Translate the **first two sentences** of the **first review** into Spanish to support Spanish-speaking customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90831b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract first two sentences from the first review\n",
    "sentences = '.'.join(reviews['Review'][0].split('.')[:2]) + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "519f9eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Initialize translation pipeline\n",
    "translator = pipeline(\n",
    "    task=\"translation_en_to_es\",\n",
    "    model=\"Helsinki-NLP/opus-mt-en-es\"\n",
    ")\n",
    "\n",
    "# Translate\n",
    "translated_sentences = translator(sentences, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2600660",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_review = translated_sentences[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e10d2a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Estoy muy satisfecho con mi Nissan NV SL 2014. Uso esta camioneta para mis entregas de negocios y uso personal.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45da432",
   "metadata": {},
   "source": [
    "#### âœ… BLEU Score Evaluation\n",
    "\n",
    "BLEU measures translation quality by comparing generated text to human reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f21221b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference translation from file\n",
    "with open(\"reference_translations.txt\", \"r\") as r:\n",
    "    translation_references = r.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7966538f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Estoy muy satisfecho con mi Nissan NV SL 2014. Utilizo esta camioneta para mis entregas comerciales y uso personal.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6842c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.6888074582865503\n"
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu_compute = bleu.compute(\n",
    "    predictions=[translated_review],\n",
    "    references=[translation_references]\n",
    ")\n",
    "\n",
    "bleu_score = bleu_compute[\"bleu\"]\n",
    "print(\"BLEU Score:\", bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5710e2",
   "metadata": {},
   "source": [
    "> âœ… **Interpretation:** A BLEU score above 0.6 indicates **high-quality translation**. The model captures the meaning accurately.\n",
    "\n",
    "> **Tip:** For production, consider using `nltk` or `sacrebleu` for more robust BLEU computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c06b20f",
   "metadata": {},
   "source": [
    "### âœ… Extractive Question Answering (QA)\n",
    "\n",
    "**Objective** Answer the question: *\"What did he like about the brand?\"* using the **second review**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8282a2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load QA pipeline\n",
    "qa_pipeline = pipeline(\n",
    "    task=\"question-answering\",\n",
    "    model=\"deepset/minilm-uncased-squad2\"\n",
    ")\n",
    "\n",
    "question = \"What did he like about the brand?\"\n",
    "\n",
    "# Get answer\n",
    "result = qa_pipeline(question=question, context=reviews['Review'][1])\n",
    "answer = result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f1f3f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ride quality, reliability\n"
     ]
    }
   ],
   "source": [
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e2c253",
   "metadata": {},
   "source": [
    "> âœ… **Insight:** The model correctly identifies the positive brand aspects mentioned in the review.\n",
    "\n",
    "> The `minilm-uncased-squad2` model is trained on SQuAD 2.0, making it ideal for extractive QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e401c401",
   "metadata": {},
   "source": [
    "### âœ… Review Summarization\n",
    "\n",
    "**Objective** Generate a concise summary of the **review**, limited to **50â€“55 tokens**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c13631af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Your min_length=56 must be inferior than your max_length=55.\n",
      "c:\\ProgramData\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1618: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (55). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "# Generate summary with max_length = 55\n",
    "summary = summarizer(reviews['Review'].iloc[-1], max_length=55)\n",
    "\n",
    "# Extract the summary text\n",
    "summarized_text = summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ee07134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  Nissan Rogue provides the desired SUV experience without burdening me with an exorbitant payment . Handling and styling are great; I have hauled 12 bags of mulch in the back with the seats down and could have held more . The engine delivers strong performance, and\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary:\", summarized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d64f8",
   "metadata": {},
   "source": [
    "> âœ… **Insight:** The summary captures key points: affordability, space, handling, and performance.\n",
    "\n",
    "> The `max_length` was limited to 55 to meet token constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7b3dc",
   "metadata": {},
   "source": [
    "### ðŸ›¡ï¸ Toxicity & Regard Analysis\n",
    "\n",
    "**Objective**\n",
    "Analyze the **summary** for:\n",
    "- **Toxicity** (harmful content)\n",
    "- **Sentiment Regard** (neutral, positive, negative, other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54c33740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default facebook/roberta-hate-speech-dynabench-r4-target checkpoint\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity Results: 0.2430584877729416\n"
     ]
    }
   ],
   "source": [
    "# Load toxicity metric\n",
    "toxicity_metric = evaluate.load(\"toxicity\")\n",
    "\n",
    "toxicity_results = toxicity_metric.compute(\n",
    "    predictions=summarized_text,\n",
    "    aggregation=\"maximum\"\n",
    ")\n",
    "\n",
    "print(\"Toxicity Results:\", toxicity_results['max_toxicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b90b243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regard Results: {'neutral': 0.928610622882843, 'positive': 0.2930169701576233, 'negative': 0.09140203893184662, 'other': 0.06192563846707344}\n"
     ]
    }
   ],
   "source": [
    "# Load regard metric (emotional tone)\n",
    "regard = evaluate.load(\"regard\")\n",
    "\n",
    "regard_results = regard.compute(\n",
    "    data=summarized_text,\n",
    "    aggregation=\"maximum\"\n",
    ")\n",
    "\n",
    "print(\"Regard Results:\", regard_results['max_regard']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e295cb6",
   "metadata": {},
   "source": [
    "> âœ… **Interpretation:**\n",
    "- **Toxicity:** Low (0.24) â†’ Safe for public use\n",
    "- **Regard:** Strongly **neutral** with a slight **positive** bias â†’ Ideal for customer-facing content\n",
    "\n",
    "> **Use Case:** This helps filter out harmful or overly negative content before displaying in chatbots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
